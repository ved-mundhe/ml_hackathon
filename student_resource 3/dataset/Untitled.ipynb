{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ceb78-3f9d-4da7-a4e9-9fbff1afb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize OCR\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def extract_text(image_path):\n",
    "    \"\"\"Extract text from an image using EasyOCR.\"\"\"\n",
    "    try:\n",
    "        result = reader.readtext(image_path, detail=0)\n",
    "        return \" \".join(result)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error extracting text from {image_path}: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean OCR text to handle any noisy characters and normalize.\"\"\"\n",
    "    text = re.sub(r'[^0-9a-zA-Z., ]', '', text)  # Remove any unwanted characters\n",
    "    return text.strip().lower()\n",
    "\n",
    "def preprocess_images(image_folder, dataset):\n",
    "    \"\"\"Apply OCR on images and clean the results.\"\"\"\n",
    "    ocr_results = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        image_path = os.path.join(image_folder, row['image_link'].split('/')[-1])\n",
    "        if not os.path.exists(image_path):\n",
    "            logging.error(f\"Image not found: {image_path}\")\n",
    "            ocr_results.append(\"\")\n",
    "            continue\n",
    "        extracted_text = extract_text(image_path)\n",
    "        cleaned_text = clean_text(extracted_text)\n",
    "        ocr_results.append(cleaned_text)\n",
    "    return ocr_results\n",
    "\n",
    "def classify_with_knn(X_train, y_train, X_test):\n",
    "    \"\"\"Train KNN classifier and make predictions on test data.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "def format_prediction(pred, unit):\n",
    "    \"\"\"Format the prediction as a value and unit.\"\"\"\n",
    "    if pred:\n",
    "        return f\"{pred} {unit}\"\n",
    "    return \"\"\n",
    "\n",
    "try:\n",
    "    # Step 1: Load the dataset and take the first 1000 rows for training\n",
    "    logging.info(\"Loading dataset and extracting the first 10 rows\")\n",
    "    train_df = pd.read_csv(\"dataset/train.csv\").head(10)\n",
    "\n",
    "    # Step 2: Preprocess images and extract text\n",
    "    logging.info(\"Applying OCR on images and preprocessing text\")\n",
    "    train_predictions = preprocess_images(\"images\", train_df)\n",
    "    train_df['predictions'] = train_predictions\n",
    "\n",
    "    # Step 3: Encode entity names\n",
    "    le = LabelEncoder()\n",
    "    train_df['entity_cluster'] = le.fit_transform(train_df['entity_name'])\n",
    "\n",
    "    # Prepare features (OCR text) and labels (entity clusters) for KNN\n",
    "    texts = train_df['predictions'].values\n",
    "    labels = train_df['entity_cluster'].values\n",
    "\n",
    "    # Use the text lengths as features for the KNN classifier\n",
    "    X_train = [[len(text)] for text in texts]\n",
    "\n",
    "    # Step 4: Train KNN classifier\n",
    "    logging.info(\"Training KNN classifier\")\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_model.fit(X_train, labels)\n",
    "\n",
    "    # Step 5: Load test set for predictions\n",
    "    test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "    logging.info(\"Applying OCR and generating predictions for test set\")\n",
    "    test_predictions = preprocess_images(\"images_test\", test_df)\n",
    "    test_df['predictions'] = test_predictions\n",
    "\n",
    "    # Use the text lengths as features for the test set\n",
    "    X_test = [[len(text)] for text in test_predictions]\n",
    "\n",
    "    # Step 6: Predict with KNN\n",
    "    test_df['entity_cluster'] = knn_model.predict(X_test)\n",
    "\n",
    "    # Step 7: Format the test predictions (example: 21.9 foot)\n",
    "    logging.info(\"Formatting test predictions\")\n",
    "    final_test_predictions = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        pred_value = row['predictions']  # This should be the numeric value extracted\n",
    "        entity_name = le.inverse_transform([row['entity_cluster']])[0]\n",
    "        final_test_predictions.append(format_prediction(pred_value, entity_name))\n",
    "\n",
    "    # Step 8: Save test_out.csv\n",
    "    test_df['prediction'] = final_test_predictions\n",
    "    test_df[['index', 'prediction']].to_csv(\"dataset/test_out.csv\", index=False)\n",
    "    logging.info(\"Test predictions saved to test_out.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
